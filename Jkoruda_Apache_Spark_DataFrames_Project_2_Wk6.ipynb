{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jPtkMdA_OWEf",
        "r2sRFJcsLkQw",
        "9_3EqMX1L5K1",
        "n02grz6wL_2O",
        "NaKt4StCMQG-",
        "vuc6XfclMVmE",
        "DchDP_CbPwT8",
        "CQ8N66HOMjHl",
        "EYOHFbc_M7R8",
        "PpZGk7PqNAJM",
        "4hP4G0T4P6_O",
        "F9rWOnFdNavj",
        "Gg-X0G1OOIYt",
        "JyjjxdRRNuTA",
        "mSH1NuyaN-oB"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6vot1-PLi70"
      },
      "source": [
        "## Apache Spark DataFrames Project\n",
        "## Instructions\n",
        "As a Data professional, you need to perform an analysis by answering questions about\n",
        "some stock market data on Safaricom from the years 2012-2017.\n",
        "\n",
        "You will need to perform the following:\n",
        "\n",
        "Data Importation and Exploration\n",
        "\n",
        "● Start a spark session and load the stock file while inferring the data types.\n",
        "● Determine the column names\n",
        "● Make observations about the schema.\n",
        "● Show the first 5 rows\n",
        "● Use the describe method to learn about the data frame\n",
        "\n",
        "Data Preparation\n",
        "\n",
        "● Format all the data to 2 decimal places i.e. format_number()\n",
        "● Create a new data frame with a column called HV Ratio that is the ratio of the\n",
        "High Price versus volume of stock traded for a day\n",
        "\n",
        "Data Analysis\n",
        "\n",
        "● What day had the Peak High in Price?\n",
        "● What is the mean of the Close column?\n",
        "● What is the max and min of the Volume column?\n",
        "● How many days was the Close lower than 60 dollars?\n",
        "● What percentage of the time was the High greater than 80 dollars?\n",
        "● What is the Pearson correlation between High and Volume?\n",
        "● What is the max High per year?\n",
        "● What is the average Close for each Calendar Month?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Hyu39xP3FD_V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPtkMdA_OWEf"
      },
      "source": [
        "## Project Deliverable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NIjZ013OX0o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab4fe7b-ab01-4e60-e851-facdcb3c0850"
      },
      "source": [
        "# Installing pyspark\n",
        "# ---\n",
        "#\n",
        "!pip install pyspark\n",
        "import pandas as pd"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5ggFX2DOccp"
      },
      "source": [
        "# Run a local spark session\n",
        "# ---\n",
        "#\n",
        "from pyspark import SparkFiles\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2sRFJcsLkQw"
      },
      "source": [
        "## 1. 2. Load data from url and save in csv file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O saf_stock.csv https://bit.ly/3pmchka\n",
        "f = open('saf_stock.csv')\n",
        "\n",
        "for i in range(0,5):\n",
        "    print(f.readline())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK4YJvQ1Hwkl",
        "outputId": "27b122a7-e394-4806-8348-a66d62aeac95"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-12 17:21:29--  https://bit.ly/3pmchka\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://archive.org/download/saf_stock/saf_stock.csv [following]\n",
            "--2023-07-12 17:21:29--  https://archive.org/download/saf_stock/saf_stock.csv\n",
            "Resolving archive.org (archive.org)... 207.241.224.2\n",
            "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ia804605.us.archive.org/18/items/saf_stock/saf_stock.csv [following]\n",
            "--2023-07-12 17:21:29--  https://ia804605.us.archive.org/18/items/saf_stock/saf_stock.csv\n",
            "Resolving ia804605.us.archive.org (ia804605.us.archive.org)... 207.241.235.94\n",
            "Connecting to ia804605.us.archive.org (ia804605.us.archive.org)|207.241.235.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90266 (88K) [text/csv]\n",
            "Saving to: ‘saf_stock.csv’\n",
            "\n",
            "saf_stock.csv       100%[===================>]  88.15K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-07-12 17:21:29 (1.18 MB/s) - ‘saf_stock.csv’ saved [90266/90266]\n",
            "\n",
            "Date,Open,High,Low,Close,Volume,Adj Close\n",
            "\n",
            "2012-01-03,59.970001,61.060001,59.869999,60.330002,12668800,52.619234999999996\n",
            "\n",
            "2012-01-04,60.209998999999996,60.349998,59.470001,59.709998999999996,9593300,52.078475\n",
            "\n",
            "2012-01-05,59.349998,59.619999,58.369999,59.419998,12768200,51.825539\n",
            "\n",
            "2012-01-06,59.419998,59.450001,58.869999,59.0,8069400,51.45922\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Determine the column names"
      ],
      "metadata": {
        "id": "eHKU4irrJtgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('saf_stock.csv')\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTXm6dnBJwe_",
        "outputId": "9cd94ca9-38fa-4d37-cf2e-de37aca54607"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Read json data from csv file and print its schema"
      ],
      "metadata": {
        "id": "AcPmK1NTIZpe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOgI8-AELUmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c9df15a-f37a-461d-84e4-dbb8568ac30b"
      },
      "source": [
        "#Reading in Data\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "# Pass in the SparkContext object `sc`\n",
        "sqlCtx = SQLContext(sc)\n",
        "\n",
        "# Read JSON data into a DataFrame object `df`\n",
        "df = sqlCtx.read.csv(\"saf_stock.csv\")\n",
        "\n",
        "df.registerTempTable('saf_stock')\n",
        "tables = sqlCtx.tableNames()\n",
        "print(tables)\n",
        "# Print the type\n",
        "print(type(df))\n",
        "\n",
        "#Schema\n",
        "#Call the printSchema() method on the Spark DataFrame df to display the schema that Spark inferred.\n",
        "df = sqlCtx.read.csv(\"saf_stock.csv\", header=True, inferSchema=True)\n",
        "df.printSchema()\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
            "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['saf_stock']\n",
            "<class 'pyspark.sql.dataframe.DataFrame'>\n",
            "root\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Show the first 5 rows"
      ],
      "metadata": {
        "id": "X1GUMWKCJd7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpeyzOQ6JVcu",
        "outputId": "7a956ce9-c6cf-4597-dc22-a60673949899"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
            "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
            "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
            "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use the describe method to learn about the data frame"
      ],
      "metadata": {
        "id": "FpZ4HA6hJMKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'select * from saf_stock'\n",
        "sqlCtx.sql(query).describe().show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvTYdWcAeiXb",
        "outputId": "9f702b54-f55a-482c-dfc2-fc6a7b042df7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|summary|       _c0|               _c1|              _c2|              _c3|              _c4|              _c5|              _c6|\n",
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "|  count|      1259|              1259|             1259|             1259|             1259|             1259|             1259|\n",
            "|   mean|      null| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
            "| stddev|      null|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
            "|    min|2012-01-03|56.389998999999996|        57.060001|        56.299999|        56.419998|         10010500|        50.363689|\n",
            "|    max|      Date|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
            "+-------+----------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "from pyspark.sql.functions import lit,when,col,expr,round\n",
        "df_prep= (\n",
        " df.withColumn('Open', F.format_number('Open', 2))\n",
        " .withColumn('High', F.format_number('High', 2))\n",
        " .withColumn('Low', F.format_number('Low', 2))\n",
        " .withColumn('Close', F.format_number('Close', 2))\n",
        " .withColumn('Volume', F.format_number('Volume', 2))\n",
        " .withColumn('Adj Close', F.format_number('Adj Close', 2)))\n",
        "df_prep.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvwviGGViq0Q",
        "outputId": "734031bf-4c82-475e-a258-5844a767bd7e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+-----+-----+-------------+---------+\n",
            "|      Date| Open| High|  Low|Close|       Volume|Adj Close|\n",
            "+----------+-----+-----+-----+-----+-------------+---------+\n",
            "|2012-01-03|59.97|61.06|59.87|60.33|12,668,800.00|    52.62|\n",
            "|2012-01-04|60.21|60.35|59.47|59.71| 9,593,300.00|    52.08|\n",
            "|2012-01-05|59.35|59.62|58.37|59.42|12,768,200.00|    51.83|\n",
            "|2012-01-06|59.42|59.45|58.87|59.00| 8,069,400.00|    51.46|\n",
            "|2012-01-09|59.03|59.55|58.92|59.18| 6,679,300.00|    51.62|\n",
            "+----------+-----+-----+-----+-----+-------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a new data frame with a column called HV Ratio that is the ratio of the\n",
        "#High Price versus volume of stock traded for a day"
      ],
      "metadata": {
        "id": "kSrYMtihRSip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit,when,col,expr,round\n",
        "df_prep= (\n",
        " df.withColumn('HV',expr(\"High/Volume\")))\n",
        "\n",
        "df_prep.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvc5_wW3RXQJ",
        "outputId": "54a94e74-69e6-4465-dba3-c40d36d1f062"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+---------+---------+------------------+--------+------------------+--------------------+\n",
            "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|                  HV|\n",
            "+----------+------------------+---------+---------+------------------+--------+------------------+--------------------+\n",
            "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|4.819714653321546E-6|\n",
            "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|6.290848613094555E-6|\n",
            "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|4.669412994783916E-6|\n",
            "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|7.367338463826307E-6|\n",
            "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|8.915604778943901E-6|\n",
            "+----------+------------------+---------+---------+------------------+--------+------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Analysis"
      ],
      "metadata": {
        "id": "5i3EySjUSTP_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAgVUquAL_QD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeadbd7d-9f9a-4b68-d073-f0a4e969fc0f"
      },
      "source": [
        "from pyspark.sql import SQLContext\n",
        "sqlCtx = SQLContext(sc)\n",
        "\n",
        "\n",
        "#Register a table in SQL\n",
        "table = df_prep.registerTempTable(\"saf_stock1\")\n",
        "\n",
        "table = sqlCtx.tableNames()\n",
        "print(table)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['saf_stock', 'saf_stock1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
            "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What day had the Peak High in Price?"
      ],
      "metadata": {
        "id": "xQMMnAa9UIVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"SELECT \\\n",
        "         Date,max(High) AS Peak_Price \\\n",
        "     FROM saf_stock1 GROUP BY Date \\\n",
        "    ORDER BY Peak_Price DESC LIMIT 1 \"\n",
        "sqlCtx.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilfwjn7jUDG5",
        "outputId": "1bb45d03-ca66-4302-b883-477f3b6535be"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|      Date|Peak_Price|\n",
            "+----------+----------+\n",
            "|2015-01-13| 90.970001|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the mean of the Close column?"
      ],
      "metadata": {
        "id": "ERJPQjuGUlbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\\\n",
        "SELECT\\\n",
        "    MEAN(Close) AS MEAN\\\n",
        "        FROM saf_stock1\"\n",
        "\n",
        "sqlCtx.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT_NAu4hUtnC",
        "outputId": "66d55730-2f4c-4f6e-b5de-88d1fba267cd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|             MEAN|\n",
            "+-----------------+\n",
            "|72.38844998012726|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n02grz6wL_2O"
      },
      "source": [
        "What is the max and min of the Volume column?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"SELECT\\\n",
        "     MIN(Volume) Min_Volume, MAX(Volume) Max_Volume\\\n",
        "         FROM saf_stock1 \"\n",
        "\n",
        "sqlCtx.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NGBedv7U9Ji",
        "outputId": "757cd1fe-1673-4f1b-f510-59e64f3e4c7b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|Min_Volume|Max_Volume|\n",
            "+----------+----------+\n",
            "|   2094900|  80898100|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many days was the Close lower than 60 dollars?"
      ],
      "metadata": {
        "id": "JNJR1TVnVRb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"SELECT  COUNT(Date) FROM saf_stock1 WHERE Close <= 60 \"\n",
        "sqlCtx.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm8po3AwVTjP",
        "outputId": "2b29cb31-012b-4742-98f5-b83089207d00"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|count(Date)|\n",
            "+-----------+\n",
            "|         81|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What percentage of the time was the High greater than 80 dollars?"
      ],
      "metadata": {
        "id": "GYNnrd8CVnqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"SELECT ROUND((COUNT(High)/1258*100),2) higher_than_80  FROM saf_stock1  WHERE High >= 80\"\n",
        "\n",
        "sqlCtx.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bEOQiZqVqSv",
        "outputId": "fa4f6845-a809-4d09-9ef8-f695137c731e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|higher_than_80|\n",
            "+--------------+\n",
            "|          9.14|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the Pearson correlation between High and Volume?\n"
      ],
      "metadata": {
        "id": "lytqOSoTWwn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"SELECT ROUND(corr(High,Volume),2) Pearson_Correlation\\\n",
        "          FROM saf_stock1\"\n",
        "\n",
        "sqlCtx.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7N6aFtxW2dk",
        "outputId": "1474ee08-0de7-4701-e437-4cee2b9092cc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|Pearson_Correlation|\n",
            "+-------------------+\n",
            "|              -0.34|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the max High per year?"
      ],
      "metadata": {
        "id": "2rg-nBiqXC1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"SELECT  EXTRACT(YEAR FROM Date) Year, MAX(High) Max_High FROM saf_stock1\\\n",
        "     GROUP BY Year ORDER BY Max_High DESC\"\n",
        "sqlCtx.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnlPKQEzXF7U",
        "outputId": "3fcca544-5b21-419e-de0d-99ad4e068300"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+\n",
            "|Year| Max_High|\n",
            "+----+---------+\n",
            "|2015|90.970001|\n",
            "|2014|88.089996|\n",
            "|2013|81.370003|\n",
            "|2012|77.599998|\n",
            "|2016|75.190002|\n",
            "+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the average Close for each Calendar Month?"
      ],
      "metadata": {
        "id": "EICdRPtLXVXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"SELECT EXTRACT(MONTH FROM Date) Month,ROUND(AVG(Close),2) Avg_Close FROM saf_stock1\\\n",
        "    GROUP BY Month ORDER BY Month ASC\"\n",
        "\n",
        "sqlCtx.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNQeaPKiXXMp",
        "outputId": "7869c273-2cde-4cdc-f6b0-a950629c7962"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+\n",
            "|Month|Avg_Close|\n",
            "+-----+---------+\n",
            "|    1|    71.45|\n",
            "|    2|    71.31|\n",
            "|    3|    71.78|\n",
            "|    4|    72.97|\n",
            "|    5|    72.31|\n",
            "|    6|     72.5|\n",
            "|    7|    74.44|\n",
            "|    8|    73.03|\n",
            "|    9|    72.18|\n",
            "|   10|    71.58|\n",
            "|   11|    72.11|\n",
            "|   12|    72.85|\n",
            "+-----+---------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}